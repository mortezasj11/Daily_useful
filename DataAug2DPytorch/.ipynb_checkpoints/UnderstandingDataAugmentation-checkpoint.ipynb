{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import splitext\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experimental_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        item = self.transform(item)\n",
    "        return item\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "x = torch.rand(4, 1, 2, 2)\n",
    "print(x)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "dataset = experimental_dataset(x,transform)\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_paths, target_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.files = os.listdir(self.image_paths)\n",
    "        self.lables = os.listdir(self.target_paths)\n",
    "\n",
    "    def transform(self, image, mask):\n",
    "        # Resize\n",
    "        resize = transforms.Resize(size=(520, 520))\n",
    "        image = resize(image)\n",
    "        mask = resize(mask)\n",
    "\n",
    "        # Random crop\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(\n",
    "            image, output_size=(512, 512))\n",
    "        image = TF.crop(image, i, j, h, w)\n",
    "        mask = TF.crop(mask, i, j, h, w)\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "\n",
    "        # Random vertical flipping\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            mask = TF.vflip(mask)\n",
    "\n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        return image, mask\n",
    "    def __len__(self):\n",
    "       \n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.files[idx]\n",
    "        label_name = self.lables[idx]\n",
    "        image = Image.open(os.path.join(self.image_paths,img_name))\n",
    "        mask = Image.open(os.path.join(self.target_paths,label_name))\n",
    "        x, y = self.transform(image, mask)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd() + \"\\n\")\n",
    "print(os.getcwd() + \"\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "def transform( CT, PET):\n",
    "    #print('CCCTTCTTCTTTTTTT',CT.shape,CT.dtype)\n",
    "\n",
    "    if torch.rand(1) < 0.5:\n",
    "        CT = TF.hflip(CT)\n",
    "        PET = TF.hflip(PET)\n",
    "\n",
    "    if torch.rand(1) < 0.5:\n",
    "        CT = TF.vflip(CT)\n",
    "        PET = TF.vflip(PET)\n",
    "\n",
    "    if torch.rand(1) < 0.5:\n",
    "        randi = torch.randint(0,360,(1,)).item()\n",
    "        CT = TF.rotate(CT, randi)\n",
    "        PET = TF.rotate(PET, randi)\n",
    "\n",
    "    return CT, PET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation test Lenna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "def transform( img):\n",
    "    #print('CCCTTCTTCTTTTTTT',CT.shape,CT.dtype)\n",
    "\n",
    "    if torch.rand(1) < 0.5:\n",
    "        img = TF.hflip(img)\n",
    "        #PET = TF.hflip(PET)\n",
    "\n",
    "    if torch.rand(1) < 0.5:\n",
    "        img = TF.vflip(img)\n",
    "        #PET = TF.vflip(PET)\n",
    "\n",
    "    if torch.rand(1) < 0.8:\n",
    "        randi = torch.randint(0,360,(1,)).item()\n",
    "        img = TF.rotate(img, randi)\n",
    "        #PET = TF.rotate(PET, randi)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform2(img):\n",
    "    \n",
    "    i,j,h, w = transforms.RandomCrop.get_params(img, output_size=(300, 300)) #(0, 0, 512, 512)\n",
    "    img = TF.crop(img, i,j,h, w) \n",
    "    img = TF.adjust_brightness(img, 1 + 0.5*(2*torch.rand(1)-1) )  \n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def transform3(img):\n",
    "\n",
    "    affine_params = tt.RandomAffine(180).get_params((-90, 90), (1, 1), (0.8, 1.2), (-45, 45),(512,512))\n",
    "    img = TF.affine(img, *affine_params)\n",
    "\n",
    "    return img\n",
    "#STATIC get_params(degrees: List[float], translate: Union[List[float], NoneType], scale_ranges: Union[List[float],\n",
    "#NoneType], shears: Union[List[float], NoneType], img_size: List[int]) â†’ Tuple[float, Tuple[int, int], float,\n",
    "# Tuple[float, float]]\n",
    "\n",
    "\n",
    "def transform4(img):\n",
    "    #tt.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=<InterpolationMode.BILINEAR: 'bilinear'>)\n",
    "    affine_params = tt.RandomAffine(0).get_params((0, 0), (0.05, 0.05), (0.85, 1.15), (-5, 5),img_size=(512,512))\n",
    "    affine_params = tt.RandomAffine(0).get_params((0, 0), (0.05, 0.05), (1.0, 1.0), (0, 0),img_size=(512,512))\n",
    "    affine_params = tt.RandomAffine(0).get_params((-180, 180), (0.0, 0.0), (0.85, 1.15), (-3, 3),img_size=(0,0))\n",
    "    img = TF.affine(img, *affine_params)\n",
    "    return img\n",
    "# torchvision.transforms.RandomAffine(degrees, translate=None, scale=None, shear=None, \n",
    "# interpolation=<InterpolationMode.NEAREST: 'nearest'>, fill=0, fillcolor=None, resample=None)\n",
    "\n",
    "\n",
    "\n",
    "x= Image.open('Lenna.png')\n",
    "\n",
    "columns = 4\n",
    "rows = 3\n",
    "fig3=plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = transform4(x)\n",
    "    fig3.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_params = tt.RandomAffine(180).get_params((-90, 90), (0, 0), (0.5, 2), (0, 0),img_size=(512,512))\n",
    "affine_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.RandomAffine(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= Image.open('Lenna.png')\n",
    "fig=plt.figure(figsize=(15, 15))\n",
    "columns = 4\n",
    "rows = 3\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = transform(x)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig2=plt.figure(figsize=(15, 15))\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = transform2(x)\n",
    "    fig2.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3=plt.figure(figsize=(15, 15))\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = transform4(x)\n",
    "    fig3.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.affine        \n",
    "    # random affine transform\n",
    "        if np.random.rand() < self.p_random_affine:\n",
    "            affine_params = T.RandomAffine(180).get_params((-90, 90), (1, 1), (2, 2), (-45, 45), self.crop)\n",
    "            image, mask = F.affine(image, *affine_params), F.affine(mask, *affine_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.histogram())\n",
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make Lenna darker\n",
    "#lena = x.pow(3)\n",
    "plt.imshow(x)\n",
    "#x.max()\n",
    "xx = np.linspace(0,1,100)\n",
    "#xx.max()\n",
    "#plt.plot(x)\n",
    "x.histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.RandomAffine(10, translate=None, scale=None,shear=None, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 0.2*torch.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.RandomCrop.get_params(img, output_size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.rand( 1 , 2 , 2 )\n",
    "#x = TF.hflip(x)\n",
    "#for i in range(8):\n",
    "    #z[i,:,:] = transform(x)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.rotate(x,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randi = torch.randint(0,360,(1,)).item()\n",
    "randi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0,360,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,h, w = transforms.RandomCrop.get_params(x, output_size=(400, 400))\n",
    "i,j,h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1*(2*torch.rand(1)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint(100,(1,)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = torch.rand((100,100)), torch.rand((100,100))\n",
    "loss = torch.mean(x*(x-y)**2)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = torch.rand((10,1,100,100)), torch.rand((10,1,100,100))\n",
    "#torch.sqrt(x)\n",
    "loss3 = torch.mean(x*(x - y)**2)\n",
    "loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(x.shape[0]):\n",
    "    (x*(x - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_parm = {\"Weights\":(1,1,1),\"batch_size\":16,\"LR\":0.001}\n",
    "W1, W2, W3, batch_size = dict_parm[\"Weights\"],dict_parm[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict = {\"mse_loss\":1.0 ,  \"Pet*mse_loss\": 0.0, 'ssim_loss': 0.0}\n",
    "weights = (weights_dict[\"mse_loss\"], weights_dict[\"Pet*mse_loss\"],weights_dict['ssim_loss'])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(a):\n",
    "    return a,a+1,a+2\n",
    "b,c = a(13)\n",
    "b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# With square kernels and equal stride\n",
    "m = nn.ConvTranspose2d(1, 64, 3, stride=2)\n",
    "input = torch.randn(4, 1, 512, 512)\n",
    "output = m(input)\n",
    "\n",
    "downsample = nn.Conv2d(1, 64, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(64, 32, 2, stride=2, padding=0)\n",
    "upsample = nn.ConvTranspose2d(64, 32, 2, stride=2, padding=0)\n",
    "h = downsample(input)\n",
    "h.size()\n",
    "#torch.Size([1, 16, 6, 6])\n",
    "#output = upsample(h, output_size=input.size())\n",
    "output = upsample(h)\n",
    "output.size()\n",
    "#torch.Size([1, 16, 12, 12])\n",
    "\n",
    "cat = torch.cat((output, output), dim=1)\n",
    "cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_4s(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, bilinear=True):\n",
    "        super(FCN_4s, self).__init__()\n",
    "\n",
    "        # Downsampling\n",
    "        self.d_conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.d_relu1 = nn.LeakyReLU()\n",
    "        self.d_pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.d_conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.d_relu2 = nn.LeakyReLU()\n",
    "        self.d_pool2 =nn.MaxPool2d(2)\n",
    "\n",
    "        self.d_conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.d_relu3 = nn.LeakyReLU()\n",
    "        self.d_pool3 =nn.MaxPool2d(2)\n",
    "\n",
    "        self.d_conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.d_relu4 = nn.LeakyReLU()\n",
    "        self.d_pool4 =nn.MaxPool2d(2)\n",
    "\n",
    "        self.d_conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.d_relu5 = nn.LeakyReLU()\n",
    "        self.d_pool5 =nn.MaxPool2d(2)\n",
    "\n",
    "        self.d_conv6 = nn.Conv2d(512, 4096, kernel_size=7, padding=3)\n",
    "        self.d_relu6 = nn.LeakyReLU()\n",
    "\n",
    "        self.d_conv7 = nn.Conv2d(4096, 2048, kernel_size=1, padding=0)\n",
    "        self.d_relu7 = nn.LeakyReLU()\n",
    "\n",
    "        self.d_conv8 = nn.Conv2d(2048, 512, kernel_size=1, padding=0)\n",
    "        self.d_relu8 = nn.LeakyReLU()\n",
    "\n",
    "        # Upsampling\n",
    "        self.u_conv1 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        #self.u_conv1 = nn.ConvTranspose2d(1024 , 512, kernel_size=2, stride=2)\n",
    "        self.u_relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.u_conv1_ = nn.Conv2d(1024, 512, kernel_size=1, padding=0)\n",
    "        self.u_relu1_ = nn.LeakyReLU()\n",
    "        \n",
    "\n",
    "        self.u_conv2 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        #self.u_conv2 = nn.ConvTranspose2d(1024 , 512, kernel_size=2, stride=2)\n",
    "        self.u_relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.u_conv3 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        #self.u_conv2_ = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.u_relu2_ = nn.LeakyReLU()\n",
    "        \n",
    "        \n",
    "\n",
    "        #self.u_conv3 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv3 = nn.ConvTranspose2d(512 , 512, kernel_size=2, stride=2)\n",
    "        self.u_relu3 = nn.LeakyReLU()\n",
    "\n",
    "        self.u_conv4 = nn.ConvTranspose2d(512+256 , 256, kernel_size=2, stride=2)\n",
    "        self.u_relu4 = nn.LeakyReLU()\n",
    "\n",
    "        self.u_conv5 = nn.ConvTranspose2d(1024 , 512, kernel_size=2, stride=2)\n",
    "        self.u_relu5 = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):#[16,1,512,512]  (x1) (x2) (x3) (x4)\n",
    "\n",
    "        x1 = self.d_conv1(x)\n",
    "        x1 = self.d_relu1(x1)\n",
    "        x1 = self.d_pool1(x1)\n",
    "\n",
    "        x2 =self.d_conv2(x1)\n",
    "        x2 =self.d_relu2(x2)\n",
    "        x2 =self.d_pool2(x2) \n",
    "\n",
    "        x3 =self.d_conv3(x2)\n",
    "        x3 =self.d_relu3(x3) \n",
    "        x3 =self.d_pool3(x3)\n",
    "\n",
    "        x4 = self.d_conv4(x3) \n",
    "        x4 = self.d_relu4(x4) \n",
    "        x4 = self.d_pool4(x4) \n",
    "\n",
    "        x5 = self.d_conv5(x4) \n",
    "        x5 = self.d_relu5(x5) \n",
    "        x5 = self.d_pool5(x5) \n",
    "\n",
    "        x6 = self.d_conv6(x5) \n",
    "        x6 = self.d_relu6(x6) \n",
    "\n",
    "        x7 = self.d_conv7(x6) \n",
    "        x7 = self.d_relu7(x7) \n",
    "\n",
    "        x8 = self.d_conv8(x7) \n",
    "        x8 = self.d_relu8(x8) \n",
    "\n",
    "        # Upsampling\n",
    "        print('x1:',x1.shape)\n",
    "        print('x2:',x2.shape)\n",
    "        print('x3:',x3.shape)\n",
    "        print('x4:',x4.shape)\n",
    "        print('x5:',x5.shape)\n",
    "        print('x6:',x5.shape)\n",
    "        \n",
    "        x_u1 = self.u_conv1(torch.cat((x5, x8), dim=1)) \n",
    "        x_u1 = self.u_relu1(x_u1)\n",
    "        print('x_u1:',x_u1.shape)\n",
    "        \n",
    "        x_u1_ = self.u_conv1_(x_u1)\n",
    "        x_u1_ = self.u_relu1_(x_u1_)\n",
    "        print('x_u1_:',x_u1_.shape)\n",
    "\n",
    "        x_u2 = self.u_conv2(torch.cat((x4, x_u1_), dim=1)) \n",
    "        x_u2 = self.u_relu2(x_u2) \n",
    "        print('x_u2:',x_u2.shape)\n",
    "        \n",
    "        x_u2_c = self.u_conv2_(x_u2) \n",
    "        x_u2_c = self.u_relu2_(x_u2_c) \n",
    "        print('x_u2_:',x_u2.shape)\n",
    "        \n",
    "        x_u3 = self.u_conv3(torch.cat((x3, x_u2_c), dim=1)) \n",
    "        x_u3 = self.u_relu3(x_u3)\n",
    "        \n",
    "        x_u3_c = self.u_conv3_c(torch.cat((x3, x_u3), dim=1)) \n",
    "        x_u3_c = self.u_relu3_c(x_u3_c) \n",
    "        \n",
    "        \n",
    "        x_u4 = self.u_conv4(torch.cat((x3, x_u2_c), dim=1)) \n",
    "        x_u4 = self.u_relu4(x_u4)\n",
    "        \n",
    "        x_u3_c = self.u_conv3_c(torch.cat((x3, x_u3), dim=1)) \n",
    "        x_u3_c = self.u_relu3_c(x_u3_c) \n",
    "\n",
    "        x1 = self.u_conv4(x2) \n",
    "        x1 = self.u_relu4(x2) \n",
    "\n",
    "        x1 = self.u_conv5(x2) \n",
    "        x1 = self.u_relu5(x2) \n",
    "        \n",
    "        return logits\n",
    "    \n",
    "net = FCN_4s(1, 1)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.001, weight_decay=1e-8, momentum=0.9)\n",
    "input = torch.randn(4, 1, 512, 512)\n",
    "net.train()\n",
    "output = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_4s(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, bilinear=True):\n",
    "        super(FCN_4s, self).__init__()\n",
    "\n",
    "        # Downsampling\n",
    "        self.d_conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.d_relu1 = nn.LeakyReLU()\n",
    "\n",
    "        self.d_conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.d_relu2 = nn.LeakyReLU()\n",
    "        self.d_pool2 =nn.MaxPool2d(2)    #256\n",
    "\n",
    "        self.d_conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.d_relu3 = nn.LeakyReLU()\n",
    "        self.d_pool3 =nn.MaxPool2d(2)    #128\n",
    "\n",
    "        self.d_conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.d_relu4 = nn.LeakyReLU()\n",
    "        self.d_pool4 =nn.MaxPool2d(2)    #64\n",
    "\n",
    "        self.d_conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.d_relu5 = nn.LeakyReLU()\n",
    "        self.d_pool5 =nn.MaxPool2d(2)    #32\n",
    "\n",
    "        self.d_conv6 = nn.Conv2d(512, 4096, kernel_size=7, padding=3)\n",
    "        self.d_relu6 = nn.LeakyReLU()\n",
    "        self.d_pool6 =nn.MaxPool2d(2)    #16\n",
    "\n",
    "        self.d_conv7 = nn.Conv2d(4096, 2048, kernel_size=1, padding=0)\n",
    "        self.d_relu7 = nn.LeakyReLU()    #16\n",
    "\n",
    "        self.d_conv8 = nn.Conv2d(2048, 512, kernel_size=1, padding=0)\n",
    "        self.d_relu8 = nn.LeakyReLU()    #16\n",
    "\n",
    "        # Upsampling\n",
    "        self.up_1 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv1 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u_relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_2 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv2 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u_relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_3 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv3 = nn.Conv2d(512+256, 512, kernel_size=3, padding=1)\n",
    "        self.u_relu3 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
    "        self.final = nn.Conv2d(512, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):#[16,1,512,512]  (x1) (x2) (x3) (x4)\n",
    "\n",
    "        x1 = self.d_conv1(x)\n",
    "        x1 = self.d_relu1(x1)\n",
    "\n",
    "        x2 =self.d_conv2(x1)\n",
    "        x2 =self.d_relu2(x2)\n",
    "        x2 =self.d_pool2(x2)  #[4, 512, 256, 256]\n",
    "\n",
    "        x3 =self.d_conv3(x2)\n",
    "        x3 =self.d_relu3(x3) \n",
    "        x3 =self.d_pool3(x3)  #[4, 512, 128, 128]\n",
    "\n",
    "        x4 = self.d_conv4(x3) \n",
    "        x4 = self.d_relu4(x4) \n",
    "        x4 = self.d_pool4(x4) #[4, 512, 64, 64]\n",
    "\n",
    "        x5 = self.d_conv5(x4) \n",
    "        x5 = self.d_relu5(x5) \n",
    "        x5 = self.d_pool5(x5) #[4, 512, 32, 32]\n",
    "\n",
    "        x6 = self.d_conv6(x5) \n",
    "        x6 = self.d_relu6(x6) \n",
    "        x6 = self.d_pool6(x6)  #[4, 512, 16, 16]\n",
    "\n",
    "        x7 = self.d_conv7(x6) \n",
    "        x7 = self.d_relu7(x7) \n",
    "\n",
    "        x8 = self.d_conv8(x7) \n",
    "        x8 = self.d_relu8(x8)  #[4, 512, 16, 16]\n",
    "\n",
    "        # Upsampling\n",
    "        print('x1:',x1.shape)\n",
    "        print('x2:',x2.shape)\n",
    "        print('x3:',x3.shape)\n",
    "        print('x4:',x4.shape)\n",
    "        print('x5:',x5.shape)\n",
    "        print('x6:',x6.shape)\n",
    "        print('x8:',x8.shape)\n",
    "        \n",
    "        x_u1 = self.up_1(x8) #[4, 512, 32, 32]     \n",
    "        x_uc1 = self.u_conv1(torch.cat((x5, x_u1), dim=1))\n",
    "        x_ur1 = self.u_relu1(x_uc1) #[4, 512, 32, 32]\n",
    "        #print('x_ur1:',x_ur1.shape)\n",
    "        \n",
    "        x_u2 = self.up_2(x_ur1)  #[4, x, 64, 64]   \n",
    "        x_uc2 = self.u_conv2(torch.cat((x4, x_u2), dim=1))\n",
    "        x_ur2 = self.u_relu2(x_uc2) #[4, 512, 64, 64]\n",
    "        #print('x_ur2:',x_u2.shape,x_uc2.shape,x_ur2.shape,torch.cat((x4, x_u2), dim=1).shape)\n",
    "        \n",
    "        x_u3 = self.up_3(x_ur2)  #[4, x, 128, 128]   \n",
    "        x_uc3 = self.u_conv3(torch.cat((x3, x_u3), dim=1))\n",
    "        x_ur3 = self.u_relu3(x_uc3) #[4, 512, 128, 128]\n",
    "        print('x_ur3:',x_ur3.shape)\n",
    "        \n",
    "        x_ur4 = self.up_4(x_ur3)\n",
    "        final = self.final(x_ur4)\n",
    "        \n",
    "        return final\n",
    "    \n",
    "net = FCN_4s(1, 1)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.001, weight_decay=1e-8, momentum=0.9)\n",
    "input = torch.randn(4, 1, 384, 384)\n",
    "net.train()\n",
    "output = net(input)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16-\n",
    "14-28-56-112-224-448\n",
    "13-26-52-104-208-416\n",
    "12-24-48-96-192-384\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_4s(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, bilinear=True):\n",
    "        super(FCN_4s, self).__init__()\n",
    "\n",
    "        # Downsampling\n",
    "        self.d_conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.d_relu1 = nn.LeakyReLU()\n",
    "\n",
    "        self.d_conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.d_relu2 = nn.LeakyReLU()\n",
    "        self.d_pool2 =nn.MaxPool2d(2)    #256\n",
    "\n",
    "        self.d_conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.d_relu3 = nn.LeakyReLU()\n",
    "        self.d_pool3 =nn.MaxPool2d(2)    #128\n",
    "\n",
    "        self.d_conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.d_relu4 = nn.LeakyReLU()\n",
    "        self.d_pool4 =nn.MaxPool2d(2)    #64\n",
    "\n",
    "        self.d_conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.d_relu5 = nn.LeakyReLU()\n",
    "        self.d_pool5 =nn.MaxPool2d(2)    #32\n",
    "\n",
    "        self.d_conv6 = nn.Conv2d(512, 4096, kernel_size=7, padding=3)\n",
    "        self.d_relu6 = nn.LeakyReLU()\n",
    "        self.d_pool6 =nn.MaxPool2d(2)    #16\n",
    "\n",
    "        self.d_conv7 = nn.Conv2d(4096, 2048, kernel_size=1, padding=0)\n",
    "        self.d_relu7 = nn.LeakyReLU()    #16\n",
    "\n",
    "        self.d_conv8 = nn.Conv2d(2048, 512, kernel_size=1, padding=0)\n",
    "        self.d_relu8 = nn.LeakyReLU()    #16\n",
    "\n",
    "        # Upsampling\n",
    "        self.up_1 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv1 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u_relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_2 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv2 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u_relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_3 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv3 = nn.Conv2d(512+256, 512, kernel_size=3, padding=1)\n",
    "        self.u_relu3 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
    "        self.final = nn.Conv2d(512, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):#[16,1,512,512]  (x1) (x2) (x3) (x4)\n",
    "\n",
    "        x1 = self.d_conv1(x)\n",
    "        x1 = self.d_relu1(x1)\n",
    "\n",
    "        x2 =self.d_conv2(x1)\n",
    "        x2 =self.d_relu2(x2)\n",
    "        x2 =self.d_pool2(x2)  #[4, 512, 256, 256]\n",
    "\n",
    "        x3 =self.d_conv3(x2)\n",
    "        x3 =self.d_relu3(x3) \n",
    "        x3 =self.d_pool3(x3)  #[4, 512, 128, 128]\n",
    "\n",
    "        x4 = self.d_conv4(x3) \n",
    "        x4 = self.d_relu4(x4) \n",
    "        x4 = self.d_pool4(x4) #[4, 512, 64, 64]\n",
    "\n",
    "        x5 = self.d_conv5(x4) \n",
    "        x5 = self.d_relu5(x5) \n",
    "        x5 = self.d_pool5(x5) #[4, 512, 32, 32]\n",
    "\n",
    "        x6 = self.d_conv6(x5) \n",
    "        x6 = self.d_relu6(x6) \n",
    "        x6 = self.d_pool6(x6)  #[4, 512, 16, 16]\n",
    "\n",
    "        x7 = self.d_conv7(x6) \n",
    "        x7 = self.d_relu7(x7) \n",
    "\n",
    "        x8 = self.d_conv8(x7) \n",
    "        x8 = self.d_relu8(x8)  #[4, 512, 16, 16]\n",
    "\n",
    "        # Upsampling  \n",
    "        x = self.up_1(x8) #[4, 512, 32, 32]     \n",
    "        x = self.u_conv1(torch.cat((x5, x), dim=1))\n",
    "        x = self.u_relu1(x) #[4, 512, 32, 32]\n",
    "        \n",
    "        x = self.up_2(x)  #[4, x, 64, 64]   \n",
    "        x = self.u_conv2(torch.cat((x4, x), dim=1))\n",
    "        x = self.u_relu2(x) #[4, 512, 64, 64]\n",
    "        \n",
    "        x = self.up_3(x)  #[4, x, 128, 128]   \n",
    "        x = self.u_conv3(torch.cat((x3, x), dim=1))\n",
    "        x = self.u_relu3(x) #[4, 512, 128, 128]\n",
    "        \n",
    "        x = self.up_4(x)\n",
    "        x = self.final(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = FCN_4s(1, 1)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.001, weight_decay=1e-8, momentum=0.9)\n",
    "input = torch.randn(4, 1, 384, 384)\n",
    "net.train()\n",
    "output = net(input)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_4s(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, bilinear=True):\n",
    "        super(FCN_4s, self).__init__()\n",
    "\n",
    "        # Downsampling\n",
    "        self.d_conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.d_bn1 = nn.BatchNorm2d(64)\n",
    "        self.d_relu1 = nn.LeakyReLU()\n",
    "\n",
    "        self.d_conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.d_bn2 = nn.BatchNorm2d(128)\n",
    "        self.d_relu2 = nn.LeakyReLU()\n",
    "        self.d_pool2 =nn.MaxPool2d(2)    #256\n",
    "\n",
    "        self.d_conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.d_bn3 = nn.BatchNorm2d(256)\n",
    "        self.d_relu3 = nn.LeakyReLU()\n",
    "        self.d_pool3 =nn.MaxPool2d(2)    #128\n",
    "\n",
    "        self.d_conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.d_bn4 = nn.BatchNorm2d(512)\n",
    "        self.d_relu4 = nn.LeakyReLU()\n",
    "        self.d_pool4 =nn.MaxPool2d(2)    #64\n",
    "\n",
    "        self.d_conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.d_bn5 = nn.BatchNorm2d(512)\n",
    "        self.d_relu5 = nn.LeakyReLU()\n",
    "        self.d_pool5 =nn.MaxPool2d(2)    #32\n",
    "\n",
    "        self.d_conv6 = nn.Conv2d(512, 512, kernel_size=7, padding=3)\n",
    "        self.d_bn6 = nn.BatchNorm2d(512)\n",
    "        self.d_relu6 = nn.LeakyReLU()\n",
    "        self.d_pool6 =nn.MaxPool2d(2)    #16\n",
    "\n",
    "        self.d_conv7 = nn.Conv2d(512, 512, kernel_size=1, padding=0)\n",
    "        self.d_bn7 = nn.BatchNorm2d(512)\n",
    "        self.d_relu7 = nn.LeakyReLU()    #16\n",
    "\n",
    "        self.d_conv8 = nn.Conv2d(512, 512, kernel_size=1, padding=0)\n",
    "        self.d_bn8 = nn.BatchNorm2d(512)\n",
    "        self.d_relu8 = nn.LeakyReLU()    #16\n",
    "\n",
    "        # Upsampling\n",
    "        self.up_1 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv1 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u_bn1 = nn.BatchNorm2d(512)\n",
    "        self.u_relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_2 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv2 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.u_bn2 = nn.BatchNorm2d(512)\n",
    "        self.u_relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_3 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.u_conv3 = nn.Conv2d(512+256, 256, kernel_size=3, padding=1)\n",
    "        self.u_bn3 = nn.BatchNorm2d(256)\n",
    "        self.u_relu3 = nn.LeakyReLU()\n",
    "        \n",
    "        self.up_4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
    "        self.final = nn.Conv2d(256, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):#[16,1,512,512]  (x1) (x2) (x3) (x4)\n",
    "\n",
    "        x1 = self.d_conv1(x)\n",
    "        x1 = self.d_bn1(x1)\n",
    "        x1 = self.d_relu1(x1)\n",
    "\n",
    "        x2 =self.d_conv2(x1)\n",
    "        x2 = self.d_bn2(x2)\n",
    "        x2 =self.d_relu2(x2)\n",
    "        x2 =self.d_pool2(x2)  #[4, x, 256, 256]\n",
    "\n",
    "        x3 =self.d_conv3(x2)\n",
    "        x3 = self.d_bn3(x3)\n",
    "        x3 =self.d_relu3(x3) \n",
    "        x3 =self.d_pool3(x3)  #[4, x, 128, 128]\n",
    "\n",
    "        x4 = self.d_conv4(x3) \n",
    "        x4 = self.d_bn4(x4)\n",
    "        x4 = self.d_relu4(x4) \n",
    "        x4 = self.d_pool4(x4) #[4, x, 64, 64]\n",
    "\n",
    "        x5 = self.d_conv5(x4) \n",
    "        x5 = self.d_bn5(x5)\n",
    "        x5 = self.d_relu5(x5) \n",
    "        x5 = self.d_pool5(x5) #[4, x, 32, 32]\n",
    "\n",
    "        x6 = self.d_conv6(x5) \n",
    "        x6 = self.d_bn6(x6)\n",
    "        x6 = self.d_relu6(x6) \n",
    "        x6 = self.d_pool6(x6)  #[4, x, 16, 16]\n",
    "\n",
    "        x6 = self.d_conv7(x6)\n",
    "        x6 = self.d_bn7(x6)\n",
    "        x6 = self.d_relu7(x6) \n",
    "\n",
    "        x6 = self.d_conv8(x6) \n",
    "        x6 = self.d_bn8(x6)\n",
    "        x6 = self.d_relu8(x6)  #[4, x, 16, 16]\n",
    "\n",
    "        # Upsampling  \n",
    "        x = self.up_1(x6) #[4, x, 32, 32]     \n",
    "        x = self.u_conv1(torch.cat((x5, x), dim=1))\n",
    "        x = self.u_bn1(x)\n",
    "        x = self.u_relu1(x) #[4, x, 32, 32]\n",
    "        \n",
    "        x = self.up_2(x)  #[4, x, 64, 64]   \n",
    "        x = self.u_conv2(torch.cat((x4, x), dim=1))\n",
    "        x = self.u_bn2(x)\n",
    "        x = self.u_relu2(x) #[4, x, 64, 64]\n",
    "        \n",
    "        x = self.up_3(x)  #[4, x, 128, 128]   \n",
    "        x = self.u_conv3(torch.cat((x3, x), dim=1))\n",
    "        x = self.u_bn3(x)\n",
    "        x = self.u_relu3(x) #[4, x, 128, 128]\n",
    "        \n",
    "        x = self.up_4(x)\n",
    "        x = self.final(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = FCN_4s(1, 1)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.001, weight_decay=1e-8, momentum=0.9)\n",
    "input = torch.randn(4, 1, 384, 384)\n",
    "net.train()\n",
    "output = net(input)\n",
    "\n",
    "output.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    " \n",
    "class GaussianBlurConv(nn.Module):\n",
    "    def __init__(self, channels=3):\n",
    "        super(GaussianBlurConv, self).__init__()\n",
    "        self.channels = channels\n",
    "        kernel = [[0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.01330373, 0.11098164, 0.22508352, 0.11098164, 0.01330373],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633]]\n",
    "        kernel = [[0.00296902, 0.01330621, 0.02193823, 0.01330621, 0.00296902],\n",
    "                [0.01330621, 0.0596343 , 0.09832033, 0.0596343 , 0.01330621],\n",
    "               [0.02193823, 0.09832033, 0.16210282, 0.09832033, 0.02193823],\n",
    "               [0.01330621, 0.0596343 , 0.09832033, 0.0596343 , 0.01330621],\n",
    "               [0.00296902, 0.01330621, 0.02193823, 0.01330621, 0.00296902]]\n",
    "        kernel = [[1.96519161e-05, 2.39409349e-04, 1.07295826e-03, 1.76900911e-03,\n",
    "        1.07295826e-03, 2.39409349e-04, 1.96519161e-05],\n",
    "       [2.39409349e-04, 2.91660295e-03, 1.30713076e-02, 2.15509428e-02,\n",
    "        1.30713076e-02, 2.91660295e-03, 2.39409349e-04],\n",
    "       [1.07295826e-03, 1.30713076e-02, 5.85815363e-02, 9.65846250e-02,\n",
    "        5.85815363e-02, 1.30713076e-02, 1.07295826e-03],\n",
    "       [1.76900911e-03, 2.15509428e-02, 9.65846250e-02, 1.59241126e-01,\n",
    "        9.65846250e-02, 2.15509428e-02, 1.76900911e-03],\n",
    "       [1.07295826e-03, 1.30713076e-02, 5.85815363e-02, 9.65846250e-02,\n",
    "        5.85815363e-02, 1.30713076e-02, 1.07295826e-03],\n",
    "       [2.39409349e-04, 2.91660295e-03, 1.30713076e-02, 2.15509428e-02,\n",
    "        1.30713076e-02, 2.91660295e-03, 2.39409349e-04],\n",
    "       [1.96519161e-05, 2.39409349e-04, 1.07295826e-03, 1.76900911e-03,\n",
    "        1.07295826e-03, 2.39409349e-04, 1.96519161e-05]]\n",
    "        kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
    "        kernel = np.repeat(kernel, self.channels, axis=0)\n",
    "        self.weight = nn.Parameter(data=kernel, requires_grad=False)\n",
    " \n",
    "    def __call__(self, x):\n",
    "        x = F.conv2d(x.unsqueeze(0), self.weight, padding=2, groups=self.channels)\n",
    "        return x\n",
    " \n",
    "#input_x = cv2.imread(\"kodim04.png\")\n",
    "input_x = np.array(Image.open('Lenna.png'))\n",
    "plt.imshow(input_x)\n",
    "plt.show()\n",
    "input_x = Variable(torch.from_numpy(input_x.astype(np.float32))).permute(2, 0, 1)\n",
    "gaussian_conv = GaussianBlurConv()\n",
    "out_x = gaussian_conv(input_x)\n",
    "out_x = out_x.squeeze(0).permute(1, 2, 0).data.numpy().astype(np.uint8)\n",
    "plt.imshow(out_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianTorch(x):     \n",
    "    kernel = [[0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.01330373, 0.11098164, 0.22508352, 0.11098164, 0.01330373],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633]]\n",
    "    kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
    "    print(kernel.shape)\n",
    "    kernel = np.repeat(kernel, self.channels, axis=0)\n",
    "    self.weight = nn.Parameter(data=kernel, requires_grad=False)\n",
    " \n",
    "    def __call__(self, x):\n",
    "        x = F.conv2d(x.unsqueeze(0), self.weight, padding=2, groups=self.channels)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = [[0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633],\n",
    "              [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "              [0.01330373, 0.11098164, 0.22508352, 0.11098164, 0.01330373],\n",
    "              [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "              [0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633]]\n",
    "kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
    "print(kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = [[0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633],\n",
    "              [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "              [0.01330373, 0.11098164, 0.22508352, 0.11098164, 0.01330373],\n",
    "              [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "              [0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633]]\n",
    "kernel = torch.FloatTensor(kernel).unsqueeze(0)\n",
    "print(kernel.shape)\n",
    "kernel = np.repeat(kernel, 3, axis=0)\n",
    "print(kernel.shape)\n",
    "weight = nn.Parameter(data=kernel, requires_grad=False)\n",
    "\n",
    "x = F.conv2d(x.unsqueeze(0), self.weight, padding=2, groups=self.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianTorch(x):     \n",
    "    kernel = [[0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.01330373, 0.11098164, 0.22508352, 0.11098164, 0.01330373],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633]]\n",
    "    kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
    "    print(kernel.shape)\n",
    "    kernel = np.repeat(kernel, 3, axis=0)\n",
    "    weight = nn.Parameter(data=kernel, requires_grad=False)\n",
    " \n",
    "\n",
    "    x = F.conv2d(x.unsqueeze(0), weight, padding=2, groups=3)\n",
    "    return x\n",
    "    \n",
    "input_x = np.array(Image.open('Lenna.png'))\n",
    "input_x = Variable(torch.from_numpy(input_x.astype(np.float32))).permute(2, 0, 1)\n",
    "print(input_x.shape)\n",
    "gaussian_conv = GaussianTorch(input_x)\n",
    "print(gaussian_conv.shape)\n",
    "plt.imshow(gaussian_conv.squeeze(0).permute(1, 2, 0).data.numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianTorch(x):     \n",
    "    kernel = [[0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.01330373, 0.11098164, 0.22508352, 0.11098164, 0.01330373],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633]]\n",
    "    kernel = torch.FloatTensor(kernel).unsqueeze(0)\n",
    "    print(kernel.shape)\n",
    "    kernel = np.repeat(kernel, 3, axis=0)\n",
    "    weight = nn.Parameter(data=kernel, requires_grad=False)\n",
    " \n",
    "\n",
    "    x = F.conv2d(x.unsqueeze(0), weight, padding=2, groups=3)\n",
    "    return x\n",
    "    \n",
    "input_x = np.array(Image.open('Lenna.png'))\n",
    "input_x = Variable(torch.from_numpy(input_x.astype(np.float32))).permute(2, 0, 1)\n",
    "gaussian_conv = GaussianTorch(input_x)\n",
    "plt.imshow(gaussian_conv.squeeze(0).permute(1, 2, 0).data.numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gkern(l=7, sig=1.):\n",
    "    \"\"\"\\\n",
    "    creates gaussian kernel with side length l and a sigma of sig\n",
    "    \"\"\"\n",
    "\n",
    "    ax = np.linspace(-(l - 1) / 2., (l - 1) / 2., l)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "\n",
    "    kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sig))\n",
    "\n",
    "    return kernel / np.sum(kernel)\n",
    "a= gkern()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianTorch(x):     #Applied on [1,h,w]\n",
    "    kernel = [[0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.01330373, 0.11098164, 0.22508352, 0.11098164, 0.01330373],\n",
    "                  [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                  [0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633]]\n",
    "    kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
    "    print(kernel.shape)\n",
    "    kernel = np.repeat(kernel, 3, axis=0)\n",
    "    weight = nn.Parameter(data=kernel, requires_grad=False)\n",
    " \n",
    "    x = F.conv2d(x.unsqueeze(0), weight, padding=2, groups=3)\n",
    "    return x.squeeze(0)\n",
    "    \n",
    "input_x = np.array(Image.open('Lenna.png'))\n",
    "input_x = Variable(torch.from_numpy(input_x.astype(np.float32))).permute(2, 0, 1)\n",
    "print(input_x.shape)\n",
    "gaussian_conv = GaussianTorch(input_x)\n",
    "print(gaussian_conv.shape)\n",
    "plt.imshow(gaussian_conv.permute(1, 2, 0).data.numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianTorch(x, mode=5):     #Applied on [1,h,w]\n",
    "    if mode == 5:\n",
    "        kernel = [[0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633],\n",
    "                      [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                      [0.01330373, 0.11098164, 0.22508352, 0.11098164, 0.01330373],\n",
    "                      [0.00655965, 0.05472157, 0.11098164, 0.05472157, 0.00655965],\n",
    "                      [0.00078633, 0.00655965, 0.01330373, 0.00655965, 0.00078633]]\n",
    "        padding = 2\n",
    "        \n",
    "    elif mode == 7:\n",
    "        kernel = [[1.96519161e-05, 2.39409349e-04, 1.07295826e-03, 1.76900911e-03,\n",
    "            1.07295826e-03, 2.39409349e-04, 1.96519161e-05],[2.39409349e-04, 2.91660295e-03, 1.30713076e-02, 2.15509428e-02,\n",
    "            1.30713076e-02, 2.91660295e-03, 2.39409349e-04],[1.07295826e-03, 1.30713076e-02, 5.85815363e-02, 9.65846250e-02,\n",
    "            5.85815363e-02, 1.30713076e-02, 1.07295826e-03],[1.76900911e-03, 2.15509428e-02, 9.65846250e-02, 1.59241126e-01,\n",
    "            9.65846250e-02, 2.15509428e-02, 1.76900911e-03],[1.07295826e-03, 1.30713076e-02, 5.85815363e-02, 9.65846250e-02,\n",
    "            5.85815363e-02, 1.30713076e-02, 1.07295826e-03],[2.39409349e-04, 2.91660295e-03, 1.30713076e-02, 2.15509428e-02,\n",
    "            1.30713076e-02, 2.91660295e-03, 2.39409349e-04],[1.96519161e-05, 2.39409349e-04, 1.07295826e-03, 1.76900911e-03,\n",
    "            1.07295826e-03, 2.39409349e-04, 1.96519161e-05]]\n",
    "        padding = 3\n",
    "        \n",
    "    kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
    "    #print(kernel.shape)\n",
    "    #kernel = np.repeat(kernel, 3, axis=0)\n",
    "    weight = nn.Parameter(data=kernel, requires_grad=False)\n",
    "    x = F.conv2d(x.unsqueeze(0), weight, padding=padding, groups=1)\n",
    "    return x.squeeze(0)\n",
    "    \n",
    "input_x = np.array(Image.open('Lenna.png'))[:,:,0]\n",
    "plt.imshow(input_x);plt.show()\n",
    "print(input_x.shape)\n",
    "input_x = Variable(torch.from_numpy(input_x.astype(np.float32))).unsqueeze(2).permute(2, 0, 1)\n",
    "print(input_x.shape)\n",
    "gaussian_conv = GaussianTorch(input_x)\n",
    "print(gaussian_conv.shape)\n",
    "plt.imshow(gaussian_conv.permute(1, 2, 0).data.numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = np.array(Image.open('Lenna.png'))\n",
    "img_normalized = (input_x - np.min(input_x))/(np.max(input_x)-np.min(input_x) )\n",
    "print(img_normalized.min(),img_normalized.max())\n",
    "plt.imshow(img_normalized)\n",
    "\n",
    "img_dark = img_normalized**4\n",
    "plt.imshow(img_dark)\n",
    "plt.show()\n",
    "\n",
    "def Gamma(x, num = 2.2):\n",
    "    x = x**(1/num)\n",
    "    return x\n",
    "\n",
    "plt.imshow(Gamma(img_dark))\n",
    "plt.show()\n",
    "\n",
    "x1 = np.linspace(0,1,100)\n",
    "y1 = x1**(1/2.2)\n",
    "plt.plot(x1,y1, x1, y1**2.2)\n",
    "plt.show()\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.hist(img_dark[:,:,0].squeeze())    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dark.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import splitext\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as tt\n",
    "\n",
    "\n",
    "class CT_AliveDead(Dataset):\n",
    "    def __init__(self, CT_dir):\n",
    "        \n",
    "        self.CT_dir = CT_dir\n",
    "        self.ids = [file for file in listdir(CT_dir) if not file.startswith('.')]  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @classmethod\n",
    "    def preprocessCT(cls, im, minn=-1000.0, maxx=250.0):\n",
    "        img_np = np.array(im)   #(5,512,512)\n",
    "        img_np = np.clip(img_np,minn ,maxx)\n",
    "        img_np = (img_np - minn)/(maxx-minn)      \n",
    "        return img_np\n",
    "\n",
    "\n",
    "    def transform(self, CT):\n",
    "        # Horizontal and vertical flip\n",
    "        if torch.rand(1) < 0.5:\n",
    "            CT = TF.hflip(CT)\n",
    "            PET = TF.hflip(PET)\n",
    "\n",
    "        if torch.rand(1) < 0.5:\n",
    "            CT = TF.vflip(CT)\n",
    "\n",
    "        # scaling\n",
    "        if torch.rand(1) < 0.9:\n",
    "            #affine_params = tt.RandomAffine(0).get_params((0, 0), (0, 0), (0.85, 1.15), (0, 0), img_size=(512,512))\n",
    "            affine_params = tt.RandomAffine(0).get_params((-180, 180), (0.0, 0.0), (0.85, 1.15), (-3, 3),img_size=(96,96))\n",
    "            CT = TF.affine(CT, *affine_params)\n",
    "\n",
    "        '''\n",
    "        # Rotation\n",
    "        if torch.rand(1) < 0.9:\n",
    "            randi = torch.randint(0,360,(1,)).item()\n",
    "            CT = TF.rotate(CT, randi)\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        #brightness\n",
    "        if torch.rand(1) < 0.5:\n",
    "            randi = 0.03*(2*torch.rand(1)-1)   # give uniform random between (-0.03, +0.03)\n",
    "            CT = TF.adjust_brightness(CT, 1 + randi )\n",
    "        '''\n",
    "        return CT\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.ids[i]\n",
    "        label = torch.tensor( np.fromstring(idx[-5]) )\n",
    "        CT_file = join(self.CT_dir , idx )\n",
    "\n",
    "        # Loading        \n",
    "        CT = np.load(CT_file)\n",
    "\n",
    "        # Normalizing\n",
    "        #CT = self.preprocessCT(CT)\n",
    "\n",
    "        # Data augmentation\n",
    "        CT = self.transform(  torch.from_numpy(CT) )\n",
    "\n",
    "        # To float before GaussianTorch(PET)\n",
    "        CT = CT.type(torch.FloatTensor)\n",
    "        \n",
    "        return {\n",
    "            'CT': CT,\n",
    "            'label': label\n",
    "        }\n",
    "    \n",
    "x= Image.open('Lenna.png')\n",
    "inputt = np.zeros((10,512,512))\n",
    "for i in range(10):\n",
    "    inputt[i,:,:] = np.array(x)[:,:,1]\n",
    " \n",
    "\n",
    "columns = 4\n",
    "rows = 3\n",
    "fig3=plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = transform4(inputt)\n",
    "    fig3.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__name__'==__main__:\n",
    "    dataset_train = CT_AliveDead(dir_CT, dir_PET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,h, w = transforms.RandomCrop.get_params(img, output_size=(300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,h, w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tt.CenterCrop(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
